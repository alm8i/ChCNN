{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from ./_train.csv\n",
      "Data loaded from ./_validate.csv\n",
      "Data loaded from ./_test.csv\n"
     ]
    }
   ],
   "source": [
    "from data_utils import Data\n",
    "\n",
    "\n",
    "config = json.load(open(\"./config.json\"))\n",
    "\n",
    "# Load training data\n",
    "training_data = Data(data_source=config[\"data\"][\"training_data_source\"], alphabet=config[\"data\"][\"alphabet\"],\n",
    "                         input_size=config[\"data\"][\"input_size\"],num_of_classes=config[\"data\"][\"num_of_classes\"])\n",
    "training_data.load_data()\n",
    "training_inputs, training_labels, batch_texts = training_data.get_all_data()\n",
    "\n",
    "\n",
    "# Load validation data\n",
    "validation_data = Data(data_source=config[\"data\"][\"validation_data_source\"], alphabet=config[\"data\"][\"alphabet\"],\n",
    "                           input_size=config[\"data\"][\"input_size\"], num_of_classes=config[\"data\"][\"num_of_classes\"])\n",
    "validation_data.load_data()\n",
    "validation_inputs, validation_labels, batch_texts = validation_data.get_all_data()\n",
    "\n",
    "# Load test data\n",
    "test_data = Data(data_source=config[\"data\"][\"test_data_source\"], alphabet=config[\"data\"][\"alphabet\"],\n",
    "                           input_size=config[\"data\"][\"input_size\"], num_of_classes=config[\"data\"][\"num_of_classes\"])\n",
    "test_data.load_data()\n",
    "test_inputs, test_labels, batch_texts = test_data.get_all_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout param: 0.5\n",
      "CharCNNZhang model built: \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sent_input (InputLayer)      (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 400, 128)          8960      \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 394, 256)          229632    \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_1 (Thresho (None, 394, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 131, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 125, 256)          459008    \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_2 (Thresho (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 41, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 39, 256)           196864    \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_3 (Thresho (None, 39, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 37, 256)           196864    \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_4 (Thresho (None, 37, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 35, 256)           196864    \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_5 (Thresho (None, 35, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 33, 256)           196864    \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_6 (Thresho (None, 33, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 11, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2816)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              2884608   \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_7 (Thresho (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "thresholded_re_lu_8 (Thresho (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 5,424,389\n",
      "Trainable params: 5,424,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model ###\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Flatten\n",
    "from keras.layers import Convolution1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import ThresholdedReLU\n",
    "from keras.layers import Dropout\n",
    "import keras_metrics\n",
    "\n",
    "#vars\n",
    "input_size=config[\"data\"][\"input_size\"]\n",
    "alphabet_size=config[\"data\"][\"alphabet_size\"]\n",
    "embedding_size=config[\"char_cnn_zhang\"][\"embedding_size\"]\n",
    "conv_layers=config[\"char_cnn_zhang\"][\"conv_layers\"]\n",
    "fully_connected_layers=config[\"char_cnn_zhang\"][\"fully_connected_layers\"]\n",
    "num_of_classes=config[\"data\"][\"num_of_classes\"]\n",
    "threshold=config[\"char_cnn_zhang\"][\"threshold\"]\n",
    "dropout_p=config[\"char_cnn_zhang\"][\"dropout_p\"]\n",
    "print(\"Dropout param: \"+str(dropout_p))\n",
    "optimizer=config[\"char_cnn_zhang\"][\"optimizer\"]\n",
    "loss=config[\"char_cnn_zhang\"][\"loss\"]\n",
    "\n",
    "# Input layer\n",
    "inputs = Input(shape=(input_size,), name='sent_input', dtype='int64')\n",
    "        \n",
    "# Embedding layers\n",
    "x = Embedding(alphabet_size + 1, embedding_size, input_length=input_size)(inputs)\n",
    "\n",
    "# Convolution layers\n",
    "for cl in conv_layers:\n",
    "    x = Convolution1D(cl[0], cl[1])(x)\n",
    "    x = ThresholdedReLU(threshold)(x)\n",
    "    if cl[2] != -1:\n",
    "        x = MaxPooling1D(cl[2])(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "\n",
    "# Fully connected layers\n",
    "for fl in fully_connected_layers:\n",
    "    x = Dense(fl)(x)\n",
    "    x = ThresholdedReLU(threshold)(x)\n",
    "    x = Dropout(dropout_p)(x)\n",
    "        \n",
    "# Output layer\n",
    "predictions = Dense(num_of_classes, activation='softmax')(x)\n",
    "\n",
    "# Build and compile model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[keras_metrics.precision(), keras_metrics.recall()]) #, metrics=['accuracy'])\n",
    "print(\"CharCNNZhang model built: \")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CharCNNZhang model: \n",
      "Train on 18640 samples, validate on 6213 samples\n",
      "Epoch 1/7\n",
      " - 17s - loss: 0.2826 - precision: 0.9575 - recall: 0.9069 - val_loss: 0.1016 - val_precision: 0.9910 - val_recall: 0.9925\n",
      "Epoch 2/7\n",
      " - 11s - loss: 0.0579 - precision: 0.9943 - recall: 0.9990 - val_loss: 0.0408 - val_precision: 0.9951 - val_recall: 1.0000\n",
      "Epoch 3/7\n",
      " - 11s - loss: 0.0311 - precision: 0.9974 - recall: 0.9990 - val_loss: 0.0168 - val_precision: 0.9992 - val_recall: 1.0000\n",
      "Epoch 4/7\n",
      " - 11s - loss: 0.0149 - precision: 0.9991 - recall: 0.9997 - val_loss: 0.0176 - val_precision: 0.9987 - val_recall: 1.0000\n",
      "Epoch 5/7\n",
      " - 11s - loss: 0.0157 - precision: 0.9989 - recall: 0.9997 - val_loss: 0.0098 - val_precision: 0.9997 - val_recall: 1.0000\n",
      "Epoch 6/7\n",
      " - 11s - loss: 0.0089 - precision: 0.9996 - recall: 0.9999 - val_loss: 0.0172 - val_precision: 0.9997 - val_recall: 1.0000\n",
      "Epoch 7/7\n",
      " - 11s - loss: 0.0134 - precision: 0.9991 - recall: 0.9995 - val_loss: 0.0347 - val_precision: 1.0000 - val_recall: 0.9917\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "\n",
    "epochs=config[\"training\"][\"epochs\"]\n",
    "batch_size=config[\"training\"][\"batch_size\"]\n",
    "checkpoint_every=config[\"training\"][\"checkpoint_every\"]\n",
    "    \n",
    "    \n",
    "print(\"Training CharCNNZhang model: \")\n",
    "model.fit(training_inputs, training_labels, validation_data=(validation_inputs, validation_labels),\n",
    "          epochs=epochs, batch_size=batch_size, verbose=2, callbacks=[])\n",
    "\n",
    "#model.fit(training_inputs, training_labels,\n",
    "#          epochs=epochs, batch_size=batch_size, verbose=2, callbacks=[])\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "6214/6214 [==============================] - 2s 246us/step\n",
      "loss: 3.50%\n",
      "precision: 99.90%\n",
      "recall: 99.25%\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "from keras.models import model_from_json\n",
    "import keras_metrics\n",
    "\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(optimizer=optimizer, loss=loss, metrics=[keras_metrics.precision(), keras_metrics.recall()])\n",
    "score = loaded_model.evaluate(test_inputs, test_labels, batch_size=batch_size, verbose=1)\n",
    "\n",
    "for i in range(0,len(loaded_model.metrics_names)):\n",
    "    print(\"%s: %.2f%%\" % (loaded_model.metrics_names[i], score[i]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00      3860\n",
      "           1       1.00      0.99      1.00      2170\n",
      "           2       0.82      0.95      0.88       110\n",
      "           3       1.00      0.90      0.95        48\n",
      "           4       0.38      0.81      0.52        26\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      6214\n",
      "   macro avg       0.84      0.93      0.87      6214\n",
      "weighted avg       0.99      0.99      0.99      6214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "model = loaded_model\n",
    "y_test = test_labels\n",
    "Y_test = np.argmax(y_test, axis=1) # Convert one-hot to index\n",
    "y_pred = model.predict(test_inputs)\n",
    "y_pred = np.argmax(y_pred,axis=-1)\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "# for ECMLPKDD\n",
    "# valid = 0\n",
    "# xss =  1\n",
    "# sqlinjection = 2\n",
    "# ldapinjection  = 3\n",
    "# xpathinjection  = 4\n",
    "# pathtransversal = 5\n",
    "# oscommanding  = 6\n",
    "# ssi = 7\n",
    "\n",
    "# for  CISC\n",
    "# valid = 0\n",
    "# malicious = 1\n",
    "\n",
    "# for Morzeux_HttpParamsDataset\n",
    "# valid = 0\n",
    "# sqli  = 1\n",
    "# xss   = 2\n",
    "# path-traversal = 3\n",
    "# cmdi = 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
